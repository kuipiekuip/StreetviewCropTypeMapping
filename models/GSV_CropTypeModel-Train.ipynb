{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FQaxwZtSCcRn"
      },
      "outputs": [],
      "source": [
        "# !pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhlciixJCdlW",
        "outputId": "5698e862-a475-4c2e-89f8-a85844e90bb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWZBGOIC_EDS"
      },
      "outputs": [],
      "source": [
        "label_to_int = {'null': 0, 'slecht': 1, 'matig': 2, 'redelijk': 3, 'goed': 4, 'others': 5}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Iz78yn6_S65"
      },
      "outputs": [],
      "source": [
        "def extract_patches(image, patch_size, stride):\n",
        "    patches = []\n",
        "    c, height, width = image.size()\n",
        "\n",
        "    for y in range(0, height - patch_size[1] + 1, stride):\n",
        "        for x in range(0, width - patch_size[0] + 1, stride):\n",
        "            patch = image[:, y:y + patch_size[1], x:x + patch_size[0]]\n",
        "            patches.append(patch)\n",
        "\n",
        "    return patches\n",
        "\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
        "    for images, labels in progress_bar:\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        #For ViT\n",
        "        logits = outputs.logits  # Extract the logits\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        # _, predicted = torch.max(outputs, 1)\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        progress_bar.set_postfix(loss=loss.item(), accuracy=correct/len(labels))\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct += correct\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "        # For F1 score calculation\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = total_correct / total_samples\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    per_class_f1 = f1_score(all_labels, all_preds, average=None)\n",
        "\n",
        "    return avg_loss, accuracy, f1, per_class_f1\n",
        "\n",
        "\n",
        "\n",
        "def validate_or_test(model, loader, criterion, device, patch_size, stride, desc='Val'):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_samples = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    progress_bar = tqdm(loader, desc=desc, leave=False)\n",
        "    with torch.no_grad():\n",
        "        for images, labels in progress_bar:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            batch_preds = []\n",
        "\n",
        "            for image in images:\n",
        "                # # Apply sliding window approach\n",
        "                # patches = extract_patches(image, patch_size, stride)\n",
        "                # patches = torch.stack(patches).to(device)\n",
        "\n",
        "                # # Aggregate predictions for each patch\n",
        "                # patch_outputs = model(patches)\n",
        "                # logits = patch_outputs.logits  # Extract the logits\n",
        "                # patch_predictions = torch.mean(logits, dim=0)\n",
        "                # patch_predictions = torch.mean(patch_outputs, dim=0)\n",
        "                # batch_preds.append(patch_predictions)\n",
        "\n",
        "                # Calculate the mode of the patch predictions\n",
        "\n",
        "                patches = extract_patches(image, patch_size, stride)\n",
        "                patches = torch.stack(patches).to(device)\n",
        "\n",
        "                # Aggregate predictions for each patch\n",
        "                patch_outputs = model(patches)\n",
        "                logits = patch_outputs.logits  # Extract the logits\n",
        "\n",
        "                # Calculate mode for each patch prediction\n",
        "                modes, _ = torch.mode(logits, dim=0)\n",
        "                batch_preds.append(modes)\n",
        "\n",
        "            print(batch_preds)\n",
        "            batch_preds = torch.stack(batch_preds)\n",
        "            loss = criterion(batch_preds, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(batch_preds, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "            # Update progress bar\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    per_class_f1 = f1_score(all_labels, all_preds, average=None)\n",
        "\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "    conf_matrix_percentage = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(conf_matrix_percentage, annot=True, fmt='g', cmap='Blues')\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "    return avg_loss, accuracy, f1, per_class_f1\n",
        "\n",
        "def train_and_evaluate(model, train_loader, val_loader, test_loader, model_name, num_epochs=5, patch_size=(224, 224), stride=30):\n",
        "    # Criterion, Optimizer, and Scheduler\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "    global best_val_f1\n",
        "    global best_model_weights\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_accuracy, train_f1, train_f1_per_class = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}, F1 Score: {train_f1:.4f}')\n",
        "        print(f'Train F1 Score Per Class ', train_f1_per_class)\n",
        "\n",
        "        val_loss, val_accuracy, val_f1, val_f1_per_class = validate_or_test(model, val_loader, criterion, device, patch_size, stride, desc='Val')\n",
        "        print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1 Score: {val_f1:.4f}')\n",
        "        print(f'Val F1 Score Per Class ', val_f1_per_class)\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            best_model_weights = model.state_dict()  # Save the best model weights\n",
        "\n",
        "        # Save intermediate model weights\n",
        "        torch.save(model.state_dict(), imagesRoot+f'{model_name}_epoch_{epoch}.pth')\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "    test_loss, test_accuracy, test_f1, test_f1_per_class = validate_or_test(model, test_loader, criterion, device, patch_size, stride, desc='Test')\n",
        "    print(f'Test Loss: {test_loss:.3f}, Accuracy: {test_accuracy:.3f}, F1 Score: {test_f1:.3f}, F1 Score Per Class [{test_f1_per_class[0]:.3f}')\n",
        "    print(f'Test F1 Score Per Class ', test_f1_per_class)\n",
        "\n",
        "    # After training is complete, load the best model weights\n",
        "    model.load_state_dict(best_model_weights)\n",
        "\n",
        "    # Save the best model weights\n",
        "    torch.save(model.state_dict(), imagesRoot+f'{model_name}.pth')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsA9rp76_V9U"
      },
      "outputs": [],
      "source": [
        "# Call the main function with the path to folder1\n",
        "imagesRoot = '/content/drive/MyDrive/GSV-CropType-Thailand/images/'\n",
        "\n",
        "path_to_images = imagesRoot + 'validationByClassOther1'\n",
        "train_loader, val_loader, test_loader = load_data(path_to_images)\n",
        "\n",
        "def load_pretrained_vit(num_labels):\n",
        "    model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=num_labels)\n",
        "    return model\n",
        "\n",
        "num_classes = 5  # Adjust as per your dataset\n",
        "num_epochs = 20\n",
        "# Load the pretrained ResNet-50 model\n",
        "# model = models.resnet50(pretrained=True)\n",
        "vit_model = load_pretrained_vit(num_labels=num_classes)\n",
        "\n",
        "# model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "# Initialize best F1 score for validation\n",
        "\n",
        "best_val_f1 = 0.0\n",
        "best_model_weights = None\n",
        "model_name = 'ViT1-Thailand-4cropsOther-lr2e-4-ep10'\n",
        "trained_model = train_and_evaluate(vit_model, train_loader, val_loader, test_loader, model_name, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0CX1RLOtcYU"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(trained_model.parameters(), lr=2e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "trained_model.to(device)\n",
        "patch_size=(224, 224)\n",
        "stride=30\n",
        "test_loss, test_accuracy, test_f1, test_f1_per_class = validate_or_test(trained_model, test_loader, criterion, device, patch_size, stride, desc='Test')\n",
        "print(f'Test Loss: {test_loss:.3f}, Accuracy: {test_accuracy:.3f}, F1 Score: {test_f1:.3f}, F1 Score Per Class [{test_f1_per_class[0]:.3f}')\n",
        "print(f'Test F1 Score Per Class ', test_f1_per_class)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
